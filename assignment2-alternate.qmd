---
title: "Assignment 2"
subtitle: "Due at 11:59pm on September 30."
Auther: "Troy (Shengkun) Liu & Zupeng Zeng"
format: html
editor: visual
---

You may work in pairs or individually for this assignment. Make sure you join a group in Canvas if you are working in pairs. Turn in this assignment as an HTML or PDF file to ELMS. Make sure to include the R Markdown or Quarto file that was used to generate it.

```{r}
#| message: FALSE
library(tidyverse)
library(epidatr)
library(censusapi)
```

In this assignment, you will pull from APIs to get data from various data sources and use your data wrangling skills to use them all together. You should turn in a report in PDF or HTML format that addresses all of the questions in this assignment, and describes the data that you pulled and analyzed. You do not need to include full introduction and conclusion sections like a full report, but you should make sure to answer the questions in paragraph form, and include all relevant tables and graphics.

Whenever possible, use piping and `dplyr`. Avoid hard-coding any numbers within the report as much as possible.

## Pulling from APIs

Our first data source is the Delphi COVIDcast data. You can access this using the Epidata API built by Carnegie Mellon University's Delphi Research group. Documentation for this API can be found here: <https://cmu-delphi.github.io/delphi-epidata/>. Here, we find the smoothed estimate of the proportion of people experiencing Covid-like symptoms by county from April 6, 2020 to April 14, 2020.

```{r}
#| eval: FALSE

covid <- pub_covidcast('fb-survey', 
                       'smoothed_wcli', 
                       'county', 
                       'day', 
                       time_values = c(20200406:20200414))
head(covid)
```

For more information about the data, see: <https://cmu-delphi.github.io/delphi-epidata/api/covidcast_signals.html>

Answer the following questions:

-   Change the data from long to wide format by including the estimate of Covid-like symptoms for each day as a column. There should be a column for `geo_value` as well as a column for each of the days in the dataset.

```{r}
covid_wide <- covid %>% 
  select(geo_value, time_value, value) %>%
  pivot_wider(
    names_from = time_value,
    values_from = value
  )
covid_wide
```

-   Find the mean, median, and variance of the estimate on each of the days from April 6, 2020 to April 14, 2020. (Note that this is not the appropriate way of finding the overall measures in reality because we aren't using weights)

```{r}
covid_stat <- covid %>% 
  group_by(time_value) %>% 
  summarise(covid_mean = mean(value),
            covid_median = median(value),
            covid_variance = var(value))
covid_stat
```

-   On the day of 04/06/2020, the mean of covid-like symptoms is 0.955; Median is 0.849, and variance is 0.454.

-   On the day of 04/07/2020, the mean of covid-like symptoms is 0.89; Median is 0.779, and variance is 0.341.

-   On the day of 04/08/2020, the mean of covid-like symptoms is 0.871; Median is 0.789, and variance is 0.3.

-   On the day of 04/09/2020, the mean of covid-like symptoms is 0.856; Median is 0.778, and variance is 0.278.

-   On the day of 04/10/2020, the mean of covid-like symptoms is 0.85; Median is 0.777, and variance is 0.283.

-   On the day of 04/11/2020, the mean of covid-like symptoms is 0.853; Median is 0.776, and variance is 0.264.

-   On the day of 04/12/2020, the mean of covid-like symptoms is 0.854; Median is 0.784, and variance is 0.26.

-   On the day of 04/13/2020, the mean of covid-like symptoms is 0.83; Median is 0.765, and variance is 0.244.

-   On the day of 04/14/2020, the mean of covid-like symptoms is 0.796; Median is 0.719, and variance is 0.255.

-   Which counties had the highest report Covid-like symptoms on each of the days within this range?

```{r}
top_counties <- covid %>%
  select(time_value, geo_value, value) %>% 
  group_by(time_value) %>%
  slice_max(order_by = value, n = 1)
  
top_counties
```

-   On the day of 04/06/2020, county ID of 36005 has the highest report Covid-like symptoms with a value of 3.414.
-   On the day of 04/07/2020, county ID of 36087 has the highest report Covid-like symptoms with a value of 4.586.
-   On the day of 04/08/2020, county ID of 36087 has the highest report Covid-like symptoms with a value of 5.156.
-   On the day of 04/09/2020, county ID of 36087 has the highest report Covid-like symptoms with a value of 4.631.
-   On the day of 04/10/2020, county ID of 36087 has the highest report Covid-like symptoms with a value of 4.518.
-   On the day of 04/11/2020, county ID of 36087 has the highest report Covid-like symptoms with a value of 4.292.
-   On the day of 04/12/2020, county ID of 36087 has the highest report Covid-like symptoms with a value of 4.409.
-   On the day of 04/13/2020, county ID of 36087 has the highest report Covid-like symptoms with a value of 4.691.
-   On the day of 04/14/2020, county ID of 36079 has the highest report Covid-like symptoms with a value of 3.969.

Using the API, get the actual COVID cases from the JHU Cases and Deaths (using the link above, `confirmed_7dav_incidence_prop`) from May 6, 2020 to May 14, 2020. This is the number of confirmed COVID cases per 100,000 people. Find the correlation between reported COVID-like symptoms and actual COVID cases per 100,000 people within each county a month later. Is there a relationship?

```{r}
# Obtain May data
cases_may <- pub_covidcast(
  'jhu-csse',
  'confirmed_7dav_incidence_prop',
  'county',
  'day',
  time_values = c(20200506:20200514)
) %>%
  as_tibble() %>%
  select(geo_value, time_value, incidence = value)

head(cases_may)
```

```{r}
# create date var April and May to match up the same day in later joining step
covid_april <- covid %>% 
  mutate(day = as.integer(format(time_value, "%d"))) %>%
  select(geo_value, day, covid_symptom = value)

covid_may <- covid_2 %>%
  mutate(day = as.integer(format(time_value, "%d"))) %>%
  select(geo_value, day, actual_case = value)

# combine datasets
covid_joined <- inner_join(covid_april, covid_may, by = c("geo_value", "day"))

covid_joined
```

```{r}
# Overall correlation (pooled)
overall_cor <- with(covid_joined, cor(covid_symptom, actual_case, use = "complete.obs"))
overall_cor

# Per-county correlations (need >= 3 paired days to be meaningful)
cor_by_county <- covid_joined %>%
  group_by(geo_value) %>%
  summarise(
    n = n(),
    cor_cli_cases = if (n() >= 3) cor(covid_symptom, actual_case, use = "complete.obs") else NA_real_,
    .groups = "drop"
  )

summary(cor_by_county$cor_cli_cases)
```

## Covidcast API Data + ACS

Now lets add another data set. The `censusapi` package provides a nice R interface for communicating with this API. However, before running queries we need an access key. This (easy) process can be completed here:

<https://api.census.gov/data/key_signup.html>

Once you have an access key, save it as a text file, then read this key in the `cs_key` object. We will use this object in all following API queries. Note that I called my text file `census-key.txt` â€“ yours might be different!

```{r}
cs_key <- read_file("/Users/zpzzz/Desktop/SURV727/census-key.txt")
```

You can navigate through the documentation for all Census Data APIs here: <https://www.census.gov/data/developers/data-sets.html> Documentation for the 5-year ACS API can be found here: <https://www.census.gov/data/developers/data-sets/acs-5year.html>.

In the following, we request basic socio-demographic information (population, median age, median household income, income per capita) for cities and villages in the state of Illinois. The information about the variables used here can be found here: <https://api.census.gov/data/2022/acs/acs5/variables.html>.

```{r}
acs <- getCensus(name = "acs/acs5",
                    vintage = 2020, 
                    vars = c("NAME", 
                             "B01001_001E", 
                             "B06002_001E", 
                             "B19013_001E", 
                             "B19301_001E"), 
                    region = "county", 
                    key = cs_key)
head(acs)
```

Now, it might be useful to rename the socio-demographic variables (`B01001_001E` etc.) in our data set and assign more meaningful names.

```{r}
acs <-
  acs %>%
  rename(pop = B01001_001E, 
         age = B06002_001E, 
         hh_income = B19013_001E, 
         income = B19301_001E)
```

It seems like we could try to use this location information listed above to merge this data set with the COVID data. However, we first have to clean the geography data to match the two datasets. The COVID data has a five digit geography code, with the first two digits representing the state and the last three representing the county within that state. The ACS data has this separated out. Add a new variable `location` to the ACS data that has the geography value in the same format as the COVID data.

```{r}
acs <- acs %>%
  mutate(location = sprintf("%02s%03s", state, county)) 
```

Answer the following questions with the COVID data and ACS data.

-   First, check how many counties aren't matched. Then, create a new data set by joining the two datasets. Keep only counties that appear in both data sets.

```{r}
cli_0406 <- covid %>%
  filter(time_value == 20200406L) %>%
  transmute(location = geo_value, cli0406 = value)

not_in_acs   <- anti_join(cli_0406, acs, by = "location") %>% nrow()
not_in_covid <- anti_join(acs, cli_0401, by = "location") %>% nrow()
c(not_in_acs = not_in_acs, not_in_covid = not_in_covid)

covid_acs <- inner_join(cli_0406, acs, by = "location")
covid_acs %>% glimpse()
```

-   Compute the mean of the proportion of people with covid-like illness symptoms on April 1, 2020 for counties that have an above average median household income and for those that have an below average median household income. When building your pipe, start with creating the grouping variable and then proceed with the remaining tasks. What conclusions might you draw from this?

```{r}

```

-   Is there a relationship between the median household income and the proportion of people reporting Covid-like illness symptoms? Describe the relationship and use a scatterplot.

```{r}

```

## Using Other Census Data

Suppose we wanted to use the 2020 1-year ACS instead of the 5-year ACS. Why would we be unable to do this?

*Hint: Read the documentation for the 1-year ACS*

Instead, repeat the steps above to merge the Google Trends data to the 1-year ACS from 2021 instead. Do the same analysis as above.

```{r}

```
